{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Notebook for Passive Acoustic Monitoring (PAM)\n",
    "\n",
    "This notebook guides through the preprocessing steps for the PAM project, including loading audio files, generating mel spectrograms, and saving processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "# Parameters for audio processing\n",
    "sample_rate = 22050  # Audio sampling rate (Hz)\n",
    "clip_duration = 5    # Duration of each clip in seconds\n",
    "samples_per_clip = sample_rate * clip_duration\n",
    "\n",
    "# Path to audio data and metadata\n",
    "audio_dir = '../data/raw_audio/'         # directory containing audio files\n",
    "metadata_file = '../data/train_metadata.csv'  # CSV with columns ['filename', 'species']\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_file)  # expects columns 'filename' and 'species'\n",
    "\n",
    "# Initialize lists to hold data and labels\n",
    "X = []   # will hold mel spectrogram arrays\n",
    "y = []   # will hold corresponding species labels\n",
    "\n",
    "# Process each audio file\n",
    "for idx, row in metadata.iterrows():\n",
    "    file_path = os.path.join(audio_dir, row['filename'])\n",
    "    if not os.path.exists(file_path):\n",
    "        continue  # skip missing files\n",
    "    # Load the full audio file\n",
    "    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    # Split into non-overlapping clips of fixed duration\n",
    "    for start in range(0, len(signal), samples_per_clip):\n",
    "        clip = signal[start:start + samples_per_clip]\n",
    "        # If clip is too short, skip it\n",
    "        if len(clip) < samples_per_clip:\n",
    "            continue\n",
    "        # Compute the mel spectrogram (128 mel bands)\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=clip, sr=sr, n_mels=128, hop_length=512\n",
    "        )\n",
    "        # Convert to log scale (decibels) for better representation\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        # Append to our dataset\n",
    "        X.append(mel_spec_db)\n",
    "        y.append(row['species'])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Save mel spectrograms and labels\n",
    "output_dir = '../data/processed/'\n",
    "os.makedirs(os.path.join(output_dir, 'mel_spectrograms'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
    "\n",
    "# Save mel spectrograms as images\n",
    "for i in range(len(X)):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(X[i], sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Mel Spectrogram - {y[i]}')\n",
    "    plt.savefig(os.path.join(output_dir, 'mel_spectrograms', f'{i}_{y[i]}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Save labels to a text file\n",
    "np.savetxt(os.path.join(output_dir, 'labels', 'labels.txt'), y, fmt='%s')\n",
    "\n",
    "# Display completion message\n",
    "print('Preprocessing complete! Mel spectrograms and labels have been saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}